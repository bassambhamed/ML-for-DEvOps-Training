{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:55:37.021525Z",
     "start_time": "2024-06-09T09:55:35.770536Z"
    }
   },
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install spacy large model if you are using in the first time, be patient it can take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:55:46.164408Z",
     "start_time": "2024-06-09T09:55:46.161499Z"
    }
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:55:49.331859Z",
     "start_time": "2024-06-09T09:55:48.391449Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:55:52.756993Z",
     "start_time": "2024-06-09T09:55:52.545207Z"
    }
   },
   "outputs": [],
   "source": [
    "data_log= pd.read_csv('./SAMPLE_DATA/labeled-encoded-data-samples/may_jun_jul_2021.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:55:57.605924Z",
     "start_time": "2024-06-09T09:55:57.602796Z"
    }
   },
   "outputs": [],
   "source": [
    "def balance_data(data):\n",
    "    numbers_samples=data.label.value_counts()[1]\n",
    "    df_safe = data[data.label==0].sample(numbers_samples+int(numbers_samples/2), random_state=2024)\n",
    "    df_suspecious = data[data.label==1].sample(numbers_samples, random_state=2024)\n",
    "    data_balanced = pd.concat([df_safe,df_suspecious],axis=0)\n",
    "    return data_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:56:00.830061Z",
     "start_time": "2024-06-09T09:56:00.814123Z"
    }
   },
   "outputs": [],
   "source": [
    "data_log_balanced=balance_data(data_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:56:03.172077Z",
     "start_time": "2024-06-09T09:56:03.168520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "label\n0    4033\n1    2689\nName: count, dtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_log_balanced.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:56:09.303527Z",
     "start_time": "2024-06-09T09:56:09.301056Z"
    }
   },
   "outputs": [],
   "source": [
    "#use this utility function to preprocess the text\n",
    "#1. Remove the stop words\n",
    "#2. Convert to base form using lemmatisation\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:57:03.452084Z",
     "start_time": "2024-06-09T09:56:15.202119Z"
    }
   },
   "outputs": [],
   "source": [
    "#create a new column \"preprocessed_text\" which store the clean form of given text [use apply and lambda function]\n",
    "\n",
    "data_log_balanced['preprocessed_log_line'] = data_log_balanced['log_line'].apply(lambda text: preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:57:06.242547Z",
     "start_time": "2024-06-09T09:57:06.235601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "81269     54.36.148.59 06 Jul/2021:00:51:26 -0700 /self....\n40563     85.208.98.51 31 May/2021:22:52:16 -0700 /datas...\n45812     157.55.39.45 05 Jun/2021:03:30:46 -0700 /self....\n105414    49.7.20.120 26 Jul/2021:12:35:29 -0700 http/1....\n55681     40.77.167.38 13 Jun/2021:04:06:18 -0700 /self....\nName: preprocessed_log_line, dtype: object"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_log_balanced['preprocessed_log_line'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get spacy embeddings for each preprocessed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:57:52.286274Z",
     "start_time": "2024-06-09T09:57:22.522085Z"
    }
   },
   "outputs": [],
   "source": [
    "#create a new column \"vector\" that store the vector representation of each pre-processed text\n",
    "data_log_balanced['vector'] = data_log_balanced['preprocessed_log_line'].apply(lambda text: nlp(text).vector) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:58:03.087537Z",
     "start_time": "2024-06-09T09:58:03.082911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                    preprocessed_log_line  \\\n81269   54.36.148.59 06 Jul/2021:00:51:26 -0700 /self....   \n40563   85.208.98.51 31 May/2021:22:52:16 -0700 /datas...   \n45812   157.55.39.45 05 Jun/2021:03:30:46 -0700 /self....   \n105414  49.7.20.120 26 Jul/2021:12:35:29 -0700 http/1....   \n55681   40.77.167.38 13 Jun/2021:04:06:18 -0700 /self....   \n\n                                                   vector  label  \n81269   [0.14392935, -1.8637211, -0.040199377, 0.30865...      0  \n40563   [-0.69720566, -1.4630636, 0.7257287, 0.0254308...      0  \n45812   [0.08847688, -2.0407524, 0.6192496, -0.1505259...      0  \n105414  [0.8372246, -1.3550147, -0.18667156, -0.060749...      0  \n55681   [-0.59797686, -2.1597211, -0.294015, 0.7068584...      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>preprocessed_log_line</th>\n      <th>vector</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>81269</th>\n      <td>54.36.148.59 06 Jul/2021:00:51:26 -0700 /self....</td>\n      <td>[0.14392935, -1.8637211, -0.040199377, 0.30865...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>40563</th>\n      <td>85.208.98.51 31 May/2021:22:52:16 -0700 /datas...</td>\n      <td>[-0.69720566, -1.4630636, 0.7257287, 0.0254308...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>45812</th>\n      <td>157.55.39.45 05 Jun/2021:03:30:46 -0700 /self....</td>\n      <td>[0.08847688, -2.0407524, 0.6192496, -0.1505259...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>105414</th>\n      <td>49.7.20.120 26 Jul/2021:12:35:29 -0700 http/1....</td>\n      <td>[0.8372246, -1.3550147, -0.18667156, -0.060749...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>55681</th>\n      <td>40.77.167.38 13 Jun/2021:04:06:18 -0700 /self....</td>\n      <td>[-0.59797686, -2.1597211, -0.294015, 0.7068584...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = ['preprocessed_log_line','vector','label']\n",
    "data_log_balanced[selected_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:58:17.648277Z",
     "start_time": "2024-06-09T09:58:17.636428Z"
    }
   },
   "outputs": [],
   "source": [
    "#Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_log_balanced.vector.values, \n",
    "    data_log_balanced.label, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2022,\n",
    "    stratify=data_log_balanced.label # keep the same ratio of 0 and 1 in train and test data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape the X_train and X_test so as to fit for models\n",
    "In simple terms, this code is taking a list of arrays (X_train) and stacking them along a new axis, resulting in a new two-dimensional array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:58:33.002132Z",
     "start_time": "2024-06-09T09:58:32.989349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train before reshaping:  (5377,)\n",
      "Shape of X_test before reshaping:  (1345,)\n",
      "Shape of X_train after reshaping:  (5377, 300)\n",
      "Shape of X_test after reshaping:  (1345, 300)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Shape of X_train before reshaping: \", X_train.shape)\n",
    "print(\"Shape of X_test before reshaping: \", X_test.shape)\n",
    "\n",
    "#convert the shape of X_train and X_test to 2D\n",
    "#use np.stack() function\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d =  np.stack(X_test)\n",
    "\n",
    "print(\"Shape of X_train after reshaping: \", X_train_2d.shape)\n",
    "print(\"Shape of X_test after reshaping: \", X_test_2d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:58:45.747475Z",
     "start_time": "2024-06-09T09:58:44.721156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       807\n",
      "           1       0.85      0.85      0.85       538\n",
      "\n",
      "    accuracy                           0.88      1345\n",
      "   macro avg       0.87      0.87      0.87      1345\n",
      "weighted avg       0.88      0.88      0.88      1345\n"
     ]
    }
   ],
   "source": [
    "#1. creating a Decision Tree model object\n",
    "DecisionTreeModel = DecisionTreeClassifier()\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "DecisionTreeModel.fit(X_train_2d, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = DecisionTreeModel.predict(X_test_2d)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:58:55.586351Z",
     "start_time": "2024-06-09T09:58:52.006467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       807\n",
      "           1       0.89      0.86      0.88       538\n",
      "\n",
      "    accuracy                           0.90      1345\n",
      "   macro avg       0.90      0.90      0.90      1345\n",
      "weighted avg       0.90      0.90      0.90      1345\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#1. creating a Random Forest model object\n",
    "RandomForestModel = RandomForestClassifier()\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "RandomForestModel.fit(X_train_2d, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = RandomForestModel.predict(X_test_2d)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model with some logs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The ground truth is non risky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:59:03.246232Z",
     "start_time": "2024-06-09T09:59:03.244771Z"
    }
   },
   "outputs": [],
   "source": [
    "def vectorize_log(text):\n",
    "    return nlp(text).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:59:06.989339Z",
     "start_time": "2024-06-09T09:59:06.961167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_for_prediction = '[01/Aug/2021:03:03:55 -0700] \"GET / HTTP/1.1\" 200 12883 \"-\" \"Mozilla/5.0 (Macintosh# Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML# like Gecko) Chrome/92.0.4515.107 Safari/537.36'\n",
    "log_for_prediction = preprocess(log_for_prediction)\n",
    "#reshape the vector to 2D array\n",
    "log_for_prediction = vectorize_log(log_for_prediction).reshape(-1,300)\n",
    "RandomForestModel.predict(log_for_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ground truth is risky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:59:31.664630Z",
     "start_time": "2024-06-09T09:59:31.637815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([1])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_for_prediction = '77.75.76.168 - - [01/Aug/2021:04:07:07 -0700] \"GET /honeypot/BSidesDFW%20-%202014.ipynb HTTP/1.1\" 304 265 \"-\" \"Mozilla/5.0 (compatible# SeznamBot/3.2# +http://napoveda.seznam.cz/en/seznambot-intro/)\"'\n",
    "log_for_prediction = preprocess(log_for_prediction)\n",
    "#reshape the vector to 2D array\n",
    "log_for_prediction = vectorize_log(log_for_prediction).reshape(-1,300)\n",
    "print(log_for_prediction.shape)\n",
    "RandomForestModel.predict(log_for_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:59:36.189806Z",
     "start_time": "2024-06-09T09:59:36.162409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['risky_safe_model.pkl']"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to disk\n",
    "import joblib\n",
    "filename = 'risky_safe_model.pkl'\n",
    "joblib.dump(RandomForestModel, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:59:45.267704Z",
     "start_time": "2024-06-09T09:59:45.243044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the file\n",
    "loaded_model = joblib.load('risky_safe_model.pkl')\n",
    "\n",
    "# Now, you can use loaded_model to make predictions or perform other tasks\n",
    "predictions = loaded_model.predict(log_for_prediction)\n",
    "print(type(predictions))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T10:02:38.407351Z",
     "start_time": "2024-04-15T10:02:38.402197Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
